Title: Role of open data portals
Category: Support
Handbook: yes
Tags:
Date: 2016-01-01
Slug: ogd-portals
Authors:
Summary: Foundations of how data is shared using open data portals around the world.
Lang: en
Draft: yes


### How data is cataloged and provided through portals

A data portal is a database of links to resources, not unlike a document management system. Information is often collected there by the data owners - though not always, see for example, the crowdsourced portal [Datahub.io](http://datahub.io)

Data portals are for...

> - Providing an avenue to allow the private and community sectors to add their data. It may be worthwhile to think of the catalog as the region’s catalog, rather than the regional government’s.
- Facilitating improvement of the data by allowing derivatives of datasets to be cataloged. For example, someone may geocode addresses and may wish to share those results with everybody. If you only allow single versions of datasets, these improvements remain hidden.
- Be tolerant of your data appearing elsewhere. That is, content is likely to be duplicated to communities of interest. If you have river level monitoring data available, then your data may appear in a catalog for hydrologists.
- Ensure that access is equitable. Try to avoid creating a privileged level of access for officials or tenured researchers as this will undermine community participation and engagement.

http://opendatahandbook.org/guide/en/how-to-open-up-data/#for-government

### Overview of steps involved in managing datasets

Data portals are designed to put together datasets from across many sources in one place, presenting information about them consistently, and including features that assist end users in discovering the datasets they need. They also play an important role in connecting the data publisher and end user, for instance allowing people to more easily keep track of updates and changes to datasets they are using.

Important steps in the process of uploading and managing a dataset include:

- ensuring the latest versions of content is available
- appropriate taxonometry and categorisation
- correct and complete labels and tagging (see [applying metadata](metadata))
- validating license details and contact information
- testing the ability to preview the data (if possible)

### Where is data stored

Most data portals combine datasets which are directly distributed on site, and remote datasets which are linked from the portal. Sometimes larger sized files and special requirements like geodata services are hosted externally, but in the the best case the user does not have to be aware of such details and just use the data.

### Harvesting updates with agents and scripts

For larger organisations with their own infrastructure, it becomes inconvenient and costly to upload datasets one at a time, so software programs called harvesters are used to collect details on each dataset and publish a selection of metadata to the data portal. These programs can also be run automatically to ensure that updates are propagated.

### Federation between portals

As open data portals proliferate, by some counts there are already thousands in the world, the question arises of what happens when datasets are published in multiple locations. Reaching a larger audience does not have to come with a high cost of repeated efforts to publish data: federation between portals is a kind of software contract that allows content to be shared between them: in this case, listings of open government datasets.

### Links to portals

- [Open data portals around the world](https://www.opendatasoft.com/a-comprehensive-list-of-all-open-data-portals-around-the-world/) (opendatasoft.com)
- [Dataportals.org](http://dataportals.org/)
- [Datahub.io](http://datahub.io)
